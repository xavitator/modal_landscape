{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, multiprocessing, csv\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import tqdm\n",
    "from tqdm import tnrange\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "\n",
    "import PIL.Image as IMG\n",
    "\n",
    "from imageio import imread\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de quelques constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix de l'intervalle du nombre d'images par label autorisé\n",
    "debut_lab = 99\n",
    "fin_lab = 106\n",
    "# On prend cet intervalle pour \"choisir\" le nombre de données et par exemple comparer les dataset entre eux\n",
    "# avec autant d'images dans le premier que le deuxième par exemple\n",
    "\n",
    "#Size des photos après le reshape\n",
    "size = 60\n",
    "\n",
    "#dossier de sortie des images\n",
    "folder = \"trans100/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de parsing et de téléchargement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseData(data_file):\n",
    "  csvfile = open(data_file, 'r')\n",
    "  csvreader = csv.reader(csvfile)\n",
    "  dataset = [line for line in csvreader]\n",
    "  return dataset[1:]  # Chop off header\n",
    "\n",
    "\n",
    "def DownloadImage(data):\n",
    "  (key, url, label) = data\n",
    "\n",
    "  try:\n",
    "    response = urlopen(url)\n",
    "    image_data = response.read()\n",
    "    #print(\"read\")\n",
    "  except:\n",
    "    #print('Warning: Could not download image %s from %s' % (key, url))\n",
    "    return\n",
    "\n",
    "  try:\n",
    "    pil_image = Image.open(BytesIO(image_data))\n",
    "    #print(\"parsed\")\n",
    "    return pil_image\n",
    "  except:\n",
    "    #print('Warning: Failed to parse image %s' % key)\n",
    "    return\n",
    "\n",
    "def Create_labels (data_file):\n",
    "    dataset_url = ParseData(data_file)\n",
    "    dataset = []\n",
    "    for data in tqdm.tqdm(dataset_url[:len(dataset_url)], total=len(dataset_url)) :\n",
    "        (key, url, label) = data \n",
    "        if label != \"None\" :\n",
    "            dataset.append(int(label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1225029/1225029 [00:00<00:00, 2332194.52it/s]\n",
      "100%|██████████| 1225029/1225029 [00:01<00:00, 931339.99it/s]\n"
     ]
    }
   ],
   "source": [
    "list_labels = Create_labels(\"train.csv\")\n",
    "num_labels = np.histogram(list_labels, bins=range(max(list_labels)+2))[0]\n",
    "\n",
    "#fichier contenant tous les urls des images\n",
    "dataset_url = ParseData(\"train.csv\")\n",
    "\n",
    "#selection des labels/images\n",
    "image_per_label = [0]*(15000)\n",
    "for data in tqdm.tqdm(dataset_url[:len(dataset_url)], total=len(dataset_url)):\n",
    "    (key, url, label) = data\n",
    "    if (label != \"None\") and (num_labels[int(label)]>debut_lab and num_labels[int(label)]<fin_lab) and image_per_label[int(label)]<fin_lab :\n",
    "        image_per_label[int(label)]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement effectif des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupération des transformations du TD2, contenues dans preprocessing.py\n",
    "%run couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale des images aux tailles souhaitées\n",
    "def rescale_reshape(img, size):\n",
    "    img_t = to_float32(img)\n",
    "    img_t = rescale(img,size, size)\n",
    "    return img_t\n",
    "\n",
    "#Calcul des différentes transformations\n",
    "def ajout_transfo(img, high1=0.5, low1=0.1, high2=0.2, low2=0.05) :\n",
    "    r,g,b = rgb(img) \n",
    "    bandw = rgb_to_bandw(img)\n",
    "    vis_grad_g, vis_grad_b = vis_grad(bandw)\n",
    "    vis_hessian_g, vis_hessian_b = vis_hessian(bandw)\n",
    "    return [r,g,b,\n",
    "          vis_grad_g, vis_grad_b,\n",
    "          canny_edge_detection(bandw, high1, low1),\n",
    "          canny_edge_detection(bandw, high2, low2),\n",
    "          vis_hessian_g, vis_hessian_b]\n",
    "\n",
    "#Téléchargement de l'image `t`\n",
    "def create_and_register(t):\n",
    "    i,data = t\n",
    "    (key, url, label) = data\n",
    "    if (label != \"None\") and (num_labels[int(label)]>debut_lab and num_labels[int(label)]<fin_lab) :\n",
    "        pil_image = DownloadImage(data)\n",
    "        if pil_image!= None :\n",
    "            pil_image = np.array(pil_image)\n",
    "            if len(pil_image.shape) < 3 :\n",
    "                return\n",
    "            #image_per_label[int(label)]+=1\n",
    "            pil_image = rescale_reshape(pil_image, size)\n",
    "            pil_image_li = ajout_transfo(pil_image)\n",
    "            couche = 0\n",
    "            for img in pil_image_li :\n",
    "                img = img.reshape((size, size))\n",
    "                plt.imsave(folder + str(i) + 'l' + str(label) + 'c' + str(couche) +\".png\", img, cmap=\"Greys\")\n",
    "                couche += 1\n",
    "            \n",
    "#Lancement du téléchargement des images en multiprocessing\n",
    "def CreateDataset(data_file, num_labels):\n",
    "    arg = [(i,dataset_url[i]) for i in range(len(dataset_url))]\n",
    "    with multiprocessing.Pool() as p :\n",
    "        list(tqdm.tqdm(p.imap(create_and_register, arg), total=len(dataset_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1225029/1225029 [2:50:53<00:00, 119.47it/s] \n"
     ]
    }
   ],
   "source": [
    "CreateDataset(\"train.csv\", num_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
