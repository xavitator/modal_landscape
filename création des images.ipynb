{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOIX DE LA TAILLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from skimage import data\n",
    "\n",
    "from PIL.Image import *\n",
    "\n",
    "from imageio import imread\n",
    "import glob\n",
    "from tqdm import tnrange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55462d4c84b44424be8f7e4afb694a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2883.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_images = []\n",
    "list_labels = []\n",
    "\n",
    "for image_path in tqdm(glob.glob(\"nouv_test/*.png\"), total = len(glob.glob(\"nouv_test/*.png\"))):\n",
    "    image = imread(image_path)\n",
    "    list_images.append(image)\n",
    "    debut = 10\n",
    "    fin = image_path.find('i')\n",
    "    list_labels.append(int(image_path[debut:fin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(list_labels)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_reshape(list_images, size):\n",
    "    for i in tnrange(len(list_images)) :\n",
    "        img = list_images[i]\n",
    "        img = to_float32(img)\n",
    "        img = rescale(img,size, size)\n",
    "        list_images[i] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-92ddf31ba605>:2: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(len(list_images)) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe167222d63403d975453714ad190e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2883.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rescale_reshape(list_images, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_transfo(list_images, high1=0.5, low1=0.1, high2=0.2, low2=0.05) :\n",
    "    for i in tnrange(len(list_images)) :\n",
    "        img = list_images[i]\n",
    "        r,g,b = rgb(img) \n",
    "        bandw = rgb_to_bandw(img)\n",
    "        vis_grad_g, vis_grad_b = vis_grad(bandw)\n",
    "        vis_hessian_g, vis_hessian_b = vis_hessian(bandw)\n",
    "        list_images[i] = [r,g,b,\n",
    "                          vis_grad_g, vis_grad_b,\n",
    "                          canny_edge_detection(bandw, high1, low1),\n",
    "                          canny_edge_detection(bandw, high2, low2),\n",
    "                          vis_hessian_g, vis_hessian_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-caca518f033b>:2: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(len(list_images)) :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b12828bb1d44f2ade3c9510f0e6793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2883.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ajout_transfo(list_images)\n",
    "deep = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE PAS APPELER vis_hessian A PARTIR DE MTN\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_torch(list_images, list_labels, size, deep) :\n",
    "    n = len(list_images)\n",
    "    \n",
    "    torch_images=np.array([np.array(data) for data in list_images])\n",
    "    torch_labels=np.array([np.array(data) for data in list_labels])\n",
    "    \n",
    "    torch_images = torch_images.reshape([n,deep,size,size])\n",
    "    torch_labels = torch_labels.reshape([n])\n",
    "    \n",
    "    torch_images = torch.from_numpy(torch_images)\n",
    "    torch_labels = torch.from_numpy(torch_labels)\n",
    "    \n",
    "    train_set = torch.utils.data.TensorDataset(torch_images[:int(0.8*n)],torch_labels[:int(0.8*n)])\n",
    "    test_set = torch.utils.data.TensorDataset(torch_images[int(0.8*n):],torch_labels[int(0.8*n):])\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = list_to_torch(list_images, list_labels, size, deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compteur_im = 0\n",
    "data = torch.utils.data.DataLoader(train_set, batch_size=1)\n",
    "for image, label in data :\n",
    "    image = image[0]\n",
    "    label = int(label[0])\n",
    "    for couche in range(deep) :\n",
    "        save_image(image[couche], 'nouv_trans/'+ str(compteur_im) + 'l' + str(label) + 'c' + str(couche) +'.png')\n",
    "    compteur_im +=1\n",
    "\n",
    "data = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "for image, label in data :\n",
    "    image = image[0]\n",
    "    label = int(label[0])\n",
    "    for couche in range(9) :\n",
    "        save_image(image[couche], 'nouv_trans/'+ str(compteur_im) + 'l' + str(label) + 'c' + str(couche) +'.png')\n",
    "    compteur_im +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"neb/11118image209.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut = 4\n",
    "fin = \"neb/11118image209.png\".find('i')\n",
    "label = int(\"neb/11118image209.png\"[debut:fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11118"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image\n",
    "r,g,b = rgb(img) \n",
    "bandw = rgb_to_bandw(img)\n",
    "vis_grad_g, vis_grad_b = vis_grad(bandw)\n",
    "vis_hessian_g, vis_hessian_b = vis_hessian(bandw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 512, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
